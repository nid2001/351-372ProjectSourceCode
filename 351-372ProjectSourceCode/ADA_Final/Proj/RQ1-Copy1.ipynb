{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a904b3e8-95ef-4919-b361-965f7ab8c82e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pathlib\n",
    "import multiprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26e6e18-5fef-4c44-b25a-29f5e8b3ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version：2.6.0+cu126\n",
      "CUDA Available：True\n",
      "CUDA ver：12.6\n",
      "GPU Num：1\n",
      "\n",
      "GPU 0 info：\n",
      "Dev Name：NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Dev Idx：0\n",
      "Is Cur Dev：Yes\n",
      "GPU Mem：8.00 GB\n",
      "CUDA abi：8.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version：{torch.__version__}\")\n",
    "print(f\"CUDA Available：{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA ver：{torch.version.cuda}\")\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Num：{gpu_count}\")\n",
    "else:\n",
    "    print(\"No GPU ava.\")\n",
    "\n",
    "for i in range(gpu_count):\n",
    "    print(f\"\\nGPU {i} info：\")\n",
    "    print(f\"Dev Name：{torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"Dev Idx：{i}\")\n",
    "    print(f\"Is Cur Dev：{'Yes' if torch.cuda.current_device() == i else 'No'}\")\n",
    "    print(f\"GPU Mem：{torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA abi：{torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc92b08-f74d-4269-9291-773b2dc8a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clothing_Shoes_and_Jewelry.jsonl', 'Electronics.jsonl', 'Health_and_Personal_Care.jsonl']\n",
      "['./Data/Clothing_Shoes_and_Jewelry.jsonl', './Data/Electronics.jsonl', './Data/Health_and_Personal_Care.jsonl']\n"
     ]
    }
   ],
   "source": [
    "#!!! This block determines which files are preprocessed next\n",
    "files_dir = os.listdir(\"./Data/\")\n",
    "print(files_dir)\n",
    "\n",
    "for i in range(len(files_dir)):\n",
    "    files_dir[i] = os.path.join(\"./Data/\", files_dir[i])\n",
    "\n",
    "print(files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7ed3a-80af-4919-8bc2-ccbf89c7aff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stream reads JSONL files\n",
    "with open(files_dir[0], \"r\") as f:\n",
    "    i=0\n",
    "    for line in f:\n",
    "        # Print some fields to see how they read\n",
    "        print(json.dumps(json.loads(line.strip()),indent=4))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        i = i + 1\n",
    "        if i==5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa327345-fc91-4f45-a360-84a921cd19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: stream read, distinguish by purchase, training set test set 8:2\n",
    "batch_size = 10000\n",
    "\n",
    "path = pathlib.Path(\"./Processed Data/\")\n",
    "if not path.exists():\n",
    "    os.makedirs(path)\n",
    "\n",
    "def prepro(file_path, true_reviews, false_reviews):\n",
    "    # Shuffle\n",
    "    random.shuffle(true_reviews)\n",
    "    random.shuffle(false_reviews)\n",
    "\n",
    "    # Divide training set and test set (80% training, 20% testing)\n",
    "    train_true = true_reviews[:int(0.8 * len(true_reviews))]\n",
    "    test_true = true_reviews[int(0.8 * len(true_reviews)):]\n",
    "    train_false = false_reviews[:int(0.8 * len(false_reviews))]\n",
    "    test_false = false_reviews[int(0.8 * len(false_reviews)):]\n",
    "\n",
    "    # Save training set and test set data\n",
    "    file_name = file_path.split(\"/\")[2].split(\".jsonl\")[0]\n",
    "    with open(\"./Processed Data/\" + file_name + \"_train_true\" + \".jsonl\", \"a\") as train_true_f:\n",
    "        for review in train_true:\n",
    "            train_true_f.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "    with open(\"./Processed Data/\" + file_name + \"_test_true\" + \".jsonl\", \"a\") as test_true_f:\n",
    "        for review in test_true:\n",
    "            test_true_f.write(json.dumps(review) + \"\\n\")\n",
    "        \n",
    "    with open(\"./Processed Data/\" + file_name + \"_train_false\" + \".jsonl\", \"a\") as train_false_f:\n",
    "        for review in train_false:\n",
    "            train_false_f.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "    with open(\"./Processed Data/\" + file_name + \"_test_false\" + \".jsonl\", \"a\") as test_false_f:\n",
    "        for review in test_false:\n",
    "            test_false_f.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "for file_path in files_dir:\n",
    "    # Calculate the total number of lines in the file\n",
    "    start1 = time.time()\n",
    "    with open(file_path, \"r\") as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    end1 = time.time()\n",
    "\n",
    "    # Calculate the total number of batches\n",
    "    total_batches = total_lines // batch_size + (1 if total_lines % batch_size != 0 else 0)\n",
    "\n",
    "    start2 = time.time()\n",
    "    with open(file_path, \"r\",) as f:\n",
    "        true_reviews = []\n",
    "        false_reviews = []\n",
    "        with tqdm(total=total_batches, desc=f\"Processing {file_path}\") as pbar:\n",
    "            for line in f:\n",
    "                review = json.loads(line.strip())\n",
    "    \n",
    "                if review.get(\"verified_purchase\", False):\n",
    "                    true_reviews.append(review)\n",
    "                else:\n",
    "                    false_reviews.append(review)\n",
    "    \n",
    "                if len(true_reviews) + len(false_reviews) >= batch_size:\n",
    "                    prepro(file_path, true_reviews, false_reviews)\n",
    "                    true_reviews = []\n",
    "                    false_reviews = []\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "            if true_reviews or false_reviews:\n",
    "                prepro(file_path, true_reviews, false_reviews)\n",
    "                true_reviews = []\n",
    "                false_reviews = []\n",
    "                pbar.update(1)\n",
    "    end2 = time.time()\n",
    "    print(\"{0}\".format(file_path.split(\"/\")[2]))\n",
    "    print(\"Cal num rows time：{0}ms\".format(int((end1-start1)*1000)))\n",
    "    print(\"Execute 1M lines time：{0}ms\".format(int((end2-start2)/total_lines*1000000*1000)))\n",
    "    print()\n",
    "\n",
    "print(\"Data processing and saving complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73877ec1-20f8-46e6-9eca-13608a1ebd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Stream read, differentiated by purchase, for testing only\n",
    "batch_size = 10000\n",
    "upper_limit = 500000 # if 0, no limit\n",
    "\n",
    "path = pathlib.Path(\"./Processed Data/\")\n",
    "if not path.exists():\n",
    "    os.makedirs(path)\n",
    "\n",
    "def prepro(file_path, true_reviews, false_reviews):\n",
    "    # shuffle\n",
    "    random.shuffle(true_reviews)\n",
    "    random.shuffle(false_reviews)\n",
    "\n",
    "    # Save training set and test set data\n",
    "    file_name = file_path.split(\"/\")[2].split(\".jsonl\")[0]\n",
    "    with open(\"./Processed Data/\" + file_name + \"_true\" + \".jsonl\", \"a\") as true_f:\n",
    "        for review in true_reviews:\n",
    "            true_f.write(json.dumps(review) + \"\\n\")\n",
    "        \n",
    "    with open(\"./Processed Data/\" + file_name + \"_false\" + \".jsonl\", \"a\") as false_f:\n",
    "        for review in false_reviews:\n",
    "            false_f.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "\n",
    "    \n",
    "for file_path in files_dir:\n",
    "    # Calculate the total number of lines in the file\n",
    "    start1 = time.time()\n",
    "    with open(file_path, \"r\") as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    end1 = time.time()\n",
    "\n",
    "    effective_lines = total_lines if upper_limit == 0 else min(total_lines, upper_limit)\n",
    "    \n",
    "    # Calculate the total number of batches\n",
    "    total_batches = effective_lines // batch_size + (1 if effective_lines % batch_size != 0 else 0)\n",
    "\n",
    "    start2 = time.time()\n",
    "    with open(file_path, \"r\",) as f:\n",
    "        true_reviews = []\n",
    "        false_reviews = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        with tqdm(total=total_batches, desc=f\"Processing {file_path}\") as pbar:\n",
    "            for line in f:\n",
    "                if upper_limit > 0 and processed_count >= upper_limit:\n",
    "                    break\n",
    "                    \n",
    "                review = json.loads(line.strip())\n",
    "                processed_count += 1\n",
    "    \n",
    "                if review.get(\"verified_purchase\", False):\n",
    "                    true_reviews.append(review)\n",
    "                else:\n",
    "                    false_reviews.append(review)\n",
    "    \n",
    "                if len(true_reviews) + len(false_reviews) >= batch_size:\n",
    "                    prepro(file_path, true_reviews, false_reviews)\n",
    "                    true_reviews = []\n",
    "                    false_reviews = []\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "            if true_reviews or false_reviews:\n",
    "                prepro(file_path, true_reviews, false_reviews)\n",
    "                pbar.update(1)\n",
    "    end2 = time.time()\n",
    "    print(\"{0}\".format(file_path.split(\"/\")[2]))\n",
    "    print(\"Num lines：{0}\".format(total_lines))\n",
    "    print(\"Cal num rows time：{0}ms\".format(time.strftime(\"%H:%M:%S\", time.gmtime(end1-start1))))\n",
    "    print(\"Batch num：{}\".format(total_batches))\n",
    "    print(\"Execute 1M lines tme：{0}ms\".format(time.strftime(\"%H:%M:%S\", time.gmtime((end2-start2)*1000000))))\n",
    "    print(\"Actual execute {0} lines\".format(processed_count))\n",
    "    print()\n",
    "\n",
    "print(\"Data processing and saving complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bea1a-3775-4ce3-921e-ddd270680d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "output_file = os.path.join(\"./\", \"line_counts.json\")\n",
    "\n",
    "# Count the number of lines in all JSONL files. If the file already exists, the existing content is loaded\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, \"r\") as f:\n",
    "        line_counts = json.load(f)\n",
    "else:\n",
    "    line_counts = {}\n",
    "\n",
    "# Get all JSONL files\n",
    "jsonl_files = [f for f in os.listdir(\"./Processed Data\") if f.endswith(\".jsonl\")]\n",
    "\n",
    "# Only unrecorded files are processed\n",
    "new_files = [f for f in jsonl_files if f not in line_counts]\n",
    "\n",
    "# Walk through and count the number of rows\n",
    "for file_name in tqdm(new_files, desc=\"Calculating new file line counts\"):\n",
    "    file_path = os.path.join(\"./Processed Data\", file_name)\n",
    "    \n",
    "    # Count the number of lines in the current file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    # Save to dictionary\n",
    "    line_counts[file_name] = total_lines\n",
    "\n",
    "# Save the line count results to the JSON file\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(line_counts, f, indent=4)\n",
    "\n",
    "print(f\"Complete. The row number information is saved to {output_file}. Number of statistics files added: {len(new_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d0f655-b78b-442c-953e-6edd9cf40b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clothing_Shoes_and_Jewelry_false.jsonl', 'Clothing_Shoes_and_Jewelry_true.jsonl', 'Electronics_false.jsonl', 'Electronics_true.jsonl', 'Health_and_Personal_Care_false.jsonl', 'Health_and_Personal_Care_true.jsonl']\n",
      "['./Processed Data/Clothing_Shoes_and_Jewelry_false.jsonl', './Processed Data/Clothing_Shoes_and_Jewelry_true.jsonl', './Processed Data/Electronics_false.jsonl', './Processed Data/Electronics_true.jsonl', './Processed Data/Health_and_Personal_Care_false.jsonl', './Processed Data/Health_and_Personal_Care_true.jsonl']\n",
      "\n",
      "['./Test Result/Clothing_Shoes_and_Jewelry_false.jsonl', './Test Result/Clothing_Shoes_and_Jewelry_true.jsonl', './Test Result/Electronics_false.jsonl', './Test Result/Electronics_true.jsonl', './Test Result/Health_and_Personal_Care_false.jsonl', './Test Result/Health_and_Personal_Care_true.jsonl']\n"
     ]
    }
   ],
   "source": [
    "test_files_dir = os.listdir(\"./Processed Data/\")\n",
    "print(test_files_dir)\n",
    "\n",
    "output_files_dir = []\n",
    "\n",
    "for i in range(len(test_files_dir)):\n",
    "    output_files_dir.append(os.path.join(\"./Test Result/\", test_files_dir[i]))\n",
    "\n",
    "for i in range(len(test_files_dir)):\n",
    "    test_files_dir[i] = os.path.join(\"./Processed Data/\", test_files_dir[i])\n",
    "\n",
    "print(test_files_dir)\n",
    "print()\n",
    "print(output_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e064ef-9de1-4378-9d12-4bcbd5766228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing hardware in use now: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\31445\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\31445\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Computing hardware in use now:\", device)\n",
    "model.to(device)\n",
    "# Put the model into evaluation mode\n",
    "model.eval()\n",
    "\n",
    "#nltk word divider\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define a function that analyzes emotion\n",
    "def predict_sentiment(texts, json_lines=None, batch_size=32):\n",
    "    try:\n",
    "        # Split text into sentences\n",
    "        sentences_list = [sent_tokenize(text) if text.strip() else [\"\"] for text in texts]\n",
    "        flat_sentences = [s for sent_list in sentences_list for s in sent_list]  # flatten\n",
    "        \n",
    "        if not flat_sentences:\n",
    "            raise ValueError(\"The text has no valid sentences!\")\n",
    "    \n",
    "        inputs = tokenizer(flat_sentences, return_tensors=\"pt\", max_length=512, padding=True, truncation=True)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}  # Push to GPU\n",
    "        \n",
    "        # Let BERT calculate the emotion score of all sentences at once\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "    \n",
    "        # Gets the logits for all sentences\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1) + 1  # 1-5 stars\n",
    "\n",
    "        # Calculates the final rating for each text\n",
    "        index = 0\n",
    "        results = []\n",
    "        for sentences in sentences_list:\n",
    "            num_sentences = len(sentences)\n",
    "            if num_sentences == 0:\n",
    "                final_prediction = 3  # Default neutral score\n",
    "            else:\n",
    "                final_prediction = round(predictions[index:index + num_sentences].float().mean().item())\n",
    "            results.append(final_prediction)\n",
    "            index += num_sentences\n",
    "\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\nBatch error:\", str(e))\n",
    "        if json_lines:\n",
    "            print(\"JSON line:\", json.dumps(json.loads(json_lines[0].strip()), indent=4))\n",
    "        return [3] * len(texts)  # avoid crash\n",
    "\n",
    "    finally:\n",
    "        for var_name in [\"inputs\", \"outputs\", \"logits\", \"predictions\"]:\n",
    "            if var_name in locals():\n",
    "                del locals()[var_name]\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c1503c-fe12-4b99-884c-6fa5eaaa0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single process compute inference function\n",
    "def process_jsonl(input_file, output_file, batch_size=32):\n",
    "    print(f\"[process_jsonl] process now: {input_file}\")\n",
    "    # Read total line num\n",
    "    with open(\"./line_counts.json\", \"r\") as f:\n",
    "        line_counts = json.load(f)\n",
    "        total_lines = line_counts.get(input_file.split(\"/\")[-1], 0)\n",
    "\n",
    "    # Check whether the output file has content, and perform breakpoint continuation processing\n",
    "    processed_lines = 0\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, \"r\") as f:\n",
    "            processed_lines = sum(1 for _ in f)\n",
    "        print(f\"A {processed_lines} record already exists and will be skipped to continue processing.\")\n",
    "\n",
    "    # Process JSONL files\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"a\") as outfile:\n",
    "        with tqdm(total=total_lines, desc=f\"Processing {input_file.split(\"/\")[2].split(\".jsonl\")[0]}\", unit=\" reviews\", initial=processed_lines) as pbar:\n",
    "            batch_texts = []\n",
    "            batch_lines = []\n",
    "            batch_reviews = []\n",
    "            \n",
    "            for line_index, line in enumerate(infile):\n",
    "                if line_index < processed_lines:\n",
    "                    continue  # skip processed line\n",
    "\n",
    "                review = json.loads(line.strip())\n",
    "        \n",
    "                # Get the text and title fields\n",
    "                title = review.get(\"title\", \"\").strip()\n",
    "                text = review.get(\"text\", \"\").strip()\n",
    "\n",
    "                # If title or text contains only Spaces, it is considered empty\n",
    "                title = title if title else None\n",
    "                text = text if text else None\n",
    "                \n",
    "                # Merge title and text\n",
    "                full_text = (title + \". \" + text) if title and text else (title or text or \"\")\n",
    "\n",
    "                batch_texts.append(full_text)\n",
    "                batch_lines.append(line)\n",
    "                batch_reviews.append(review)\n",
    "\n",
    "                # When accumulated to batch_size, batch prediction is performed\n",
    "                if len(batch_texts) >= batch_size:\n",
    "                    predictions = predict_sentiment(batch_texts, batch_lines, batch_size=batch_size)\n",
    "                    for i, review in enumerate(batch_reviews):\n",
    "                        review[\"predict_stars\"] = predictions[i]\n",
    "                        outfile.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "                    batch_texts.clear()\n",
    "                    batch_lines.clear()\n",
    "                    batch_reviews.clear()\n",
    "                    pbar.update(batch_size)\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    \n",
    "            # Process the remaining data\n",
    "            if batch_texts:\n",
    "                predictions = predict_sentiment(batch_texts, batch_lines, batch_size=batch_size)\n",
    "                for i, review in enumerate(batch_reviews):\n",
    "                    review[\"predict_stars\"] = predictions[i]\n",
    "                    outfile.write(json.dumps(review) + \"\\n\")\n",
    "\n",
    "                pbar.update(len(batch_texts))\n",
    "    \n",
    "    print(\"Processing complete! A new file has been generated: \", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf5542b-5454-4a80-9afe-bf3b21b75dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_file = \"./process_status.json\"\n",
    "\n",
    "# Load processed state\n",
    "if os.path.exists(status_file):\n",
    "    with open(status_file, \"r\") as f:\n",
    "        process_status = json.load(f)\n",
    "else:\n",
    "    process_status = {}\n",
    "\n",
    "# Single threaded inference\n",
    "for i in range(len(test_files_dir)):\n",
    "    input_file = test_files_dir[i]\n",
    "    output_file = output_files_dir[i]\n",
    "    file_name = os.path.basename(input_file)\n",
    "\n",
    "    if process_status.get(file_name) == \"done\":\n",
    "        print(f\"File {file_name} has been processed, skipped.\")\n",
    "        continue\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"\\n Start processing file: {file_name}\")\n",
    "\n",
    "    process_jsonl(input_file, output_file, batch_size=40) # batch_size change here!\n",
    "\n",
    "    print(f\"Processing completed: {file_name}\")\n",
    "    end = time.time()\n",
    "    print(\"Time use：{0}\".format(time.strftime(\"%H:%M:%S\", time.gmtime(end-start))))\n",
    "\n",
    "    # Mark as processed\n",
    "    process_status[file_name] = \"done\"\n",
    "    with open(status_file, \"w\") as f:\n",
    "        json.dump(process_status, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cadf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
